---
title: "tensorflowモデルのマルチワーカTPUでのトレーニング"
emoji: "🪢"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["tensorflow", "googlecloud", "TPU"]
published: false
---
bertの上に作った文章分類モデルをtensorflowで動かしているのですが、ファインチューニングをTPU v5e-16でやることになりました。
v3-8からの移行で最初はプログラムの変更は必要ないだろうと思っていたのが予想に反して大変なことなってしまったので、原理的なところだけになりますが紹介します。

## TPU VMの構造
TPU VMは[VM types](https://cloud.google.com/tpu/docs/v5e#vm_types)にあるように、ひとつのVMが複数のCPUを含み、それぞれのCPUにTPUチップが4個づつ接続されているという構造になっています。
これらのCPUはそれぞれ完全に独立して動いていて、IPアドレスなども個別に持っています。そしてひとつのモデルをファインチューニングするためにそれらを協調して動作させるのは(少なくとも現状のtensorflow(2.19.0)では)ユーザープログラムの仕事になります。これが大変なことなってしまった原因です。

## tensorflowがimportできて正常動作するまで
tensorflowの正常動作の確認として次のようなプログラムを動かすことを第一の目標にします、これはtf.distribute.Strategyのもとでデータが分配/統合されるのを確認するものです。
https://github.com/ShoKSNeko/mwtpu/blob/master/run_strategy.py
まずCPU版、tf.distribute.Strategyの挙動を確認するためにCPUデバイスが複数ある状態を人工的に作っています。
